# ğŸŒ MultiLanguage Code Assistant using CodeLlama

An intelligent **multi-language code assistant** built with **Gradio** and powered by **CodeLlama via Ollama** â€” capable of understanding, generating, and explaining code across multiple programming languages through **text and voice**.  
This project combines **real-time streaming responses**, **speech-to-text input**, and a **modern gradient UI** to deliver an interactive AI coding experience locally.

---

## ğŸ–¼ï¸ Demo

### Below is a snapshot of the running application ğŸ‘‡  
![App Demo](images/main_page.png)

---


## ğŸš€ Features

âœ… **Supports Multiple Programming Languages**
> Generate, debug, or explain code in Python, Java, C++, JavaScript, and more.

ğŸ¤ **Voice Input Support**
> Speak your coding questions directly â€” powered by `speech_recognition`.

âš¡ **Live Streaming Output**
> See responses appear in real-time with auto-scrolling output box.

ğŸ¨ **Modern UI**
> Built using Gradioâ€™s latest features with a soft gradient background and theme.

ğŸ§  **Local Inference with Ollama**
> Runs fully offline with CodeLlama or any local GGUF model of your choice.

---

## ğŸ§© Tech Stack

| Component | Description |
|------------|-------------|
| **Ollama** | Local model server for LLMs (e.g., CodeLlama, Llama2) |
| **CodeLlama Model** | Code generation and explanation model used via Ollama |
| **Python** | Core scripting and logic implementation |
| **Gradio** | Interactive web UI |
| **SpeechRecognition** | Converts microphone input to text |
| **Requests + JSON** | Handles API communication with Ollama |

---

## ğŸ§  How It Works

1. The user provides a prompt â€” either **typed** or **spoken**.
2. The input is sent to the **Ollama local API** (`http://localhost:11434/api/generate`).
3. **CodeLlama** processes the query and returns a streaming response.
4. Gradioâ€™s interface displays the generated output in real time.

---


## ğŸ› ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/pahul1712/MultiLanguage-Code-Assistant-Using-CodeLlama.git
cd MultiLanguage-Code-Assistant-Using-CodeLlama
```

### 2ï¸âƒ£ Create a virtual environment
```bash
python3 -m venv venv
source venv/bin/activate   # For macOS/Linux
venv\Scripts\activate      # For Windows
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run Ollama and pull the model
```bash
ollama serve
ollama pull codellama
```

### 5ï¸âƒ£ Launch the app
```bash
python app.py
```

---

## ğŸ“ Repository Structure
``` bash
ğŸ“¦ MultiLanguage-Code-Assistant-Using-CodeLlama
 â”£ ğŸ“‚ images/              # Demo screenshots
 â”£ ğŸ“‚ venv/                # Virtual environment (ignored this) 
 â”£ ğŸ“œ app.py               # Main Gradio app
 â”£ ğŸ“œ modelFile            # Ollama model import file
 â”£ ğŸ“œ requirements.txt     # Python dependencies
 â”£ ğŸ“œ README.md            # Documentation
 â”£ ğŸ“œ .gitignore
```

---

## ğŸ”§ Example Prompts

- â€œWrite a Python function for binary search.â€
- â€œExplain recursion with an example in Java.â€
- â€œGenerate SQL query to find employees earning above the average salary.â€
- â€œTranslate this code from C++ to Python.â€
- â€œWrite a REST API in Flask for a to-do list.â€

---

ğŸ§‘â€ğŸ’» Author

Pahuldeep Singh Dhingra  
ğŸ“ Florida Atlantic University  
ğŸ’¼ Graduate Teaching Assistant | MS in Data Science & Analytics  
ğŸŒ [LinkedIn](https://www.linkedin.com/in/pahuldeepsing/)  | ğŸ“‘ [GitHub](https://github.com/pahul1712)  


